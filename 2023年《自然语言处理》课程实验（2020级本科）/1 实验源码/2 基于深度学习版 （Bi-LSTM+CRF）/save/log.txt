2023-0625 14:29:44 DEBUG    word_embeds.weight: torch.Size([5168, 100]), require_grad=True
2023-0625 14:29:44 DEBUG    lstm.weight_ih_l0: torch.Size([400, 100]), require_grad=True
2023-0625 14:29:44 DEBUG    lstm.weight_hh_l0: torch.Size([400, 100]), require_grad=True
2023-0625 14:29:44 DEBUG    lstm.bias_ih_l0: torch.Size([400]), require_grad=True
2023-0625 14:29:44 DEBUG    lstm.bias_hh_l0: torch.Size([400]), require_grad=True
2023-0625 14:29:44 DEBUG    lstm.weight_ih_l0_reverse: torch.Size([400, 100]), require_grad=True
2023-0625 14:29:44 DEBUG    lstm.weight_hh_l0_reverse: torch.Size([400, 100]), require_grad=True
2023-0625 14:29:44 DEBUG    lstm.bias_ih_l0_reverse: torch.Size([400]), require_grad=True
2023-0625 14:29:44 DEBUG    lstm.bias_hh_l0_reverse: torch.Size([400]), require_grad=True
2023-0625 14:29:44 DEBUG    hidden2tag.weight: torch.Size([4, 200]), require_grad=True
2023-0625 14:29:44 DEBUG    hidden2tag.bias: torch.Size([4]), require_grad=True
2023-0625 14:29:44 DEBUG    crf.start_transitions: torch.Size([4]), require_grad=True
2023-0625 14:29:44 DEBUG    crf.end_transitions: torch.Size([4]), require_grad=True
2023-0625 14:29:44 DEBUG    crf.transitions: torch.Size([4, 4]), require_grad=True
2023-0625 14:33:54 DEBUG    epoch 0-step 100 loss: 25.000072
2023-0625 14:37:47 DEBUG    epoch 0-step 200 loss: 12.217829
2023-0625 14:41:33 DEBUG    epoch 0-step 300 loss: 9.230044
2023-0625 14:45:27 DEBUG    epoch 0-step 400 loss: 7.362634
